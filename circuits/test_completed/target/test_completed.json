{"noir_version":"0.36.0+801c71880ecf8386a26737a5d8bb5b4cb164b2ab","hash":9721181366636770913,"abi":{"parameters":[{"name":"score1","type":{"kind":"field"},"visibility":"private"},{"name":"score2","type":{"kind":"field"},"visibility":"private"},{"name":"score3","type":{"kind":"field"},"visibility":"private"},{"name":"score4","type":{"kind":"field"},"visibility":"private"},{"name":"score5","type":{"kind":"field"},"visibility":"private"},{"name":"salt","type":{"kind":"field"},"visibility":"private"}],"return_type":{"abi_type":{"kind":"field"},"visibility":"public"},"error_types":{}},"bytecode":"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","debug_symbols":"1djBbuIwEAbgd8mZgz3jsce8ygpVoaVVpChUQFdaId59w+46pa57+JN2Vd8w8fdjjR0n+Nw87LYvT3fd8Lg/Nusf56bf37enbj+MrXNj/nx1fG6Ha+t4ag+nZq2WVs1ueBg/kVxWzWPX75p1MJfNqrEoIBQwChwKBAUeBQEFioIIT1x5qp1JQjgXFhYEC4aFg4XAwsMiwEJhEVFB5Tn3moTaXFhYECwYFg4WAgsPiwALhUVEBZfnPPp/IpqYCwsLggXDwsFCYOFhEWChsIiocMU5j+SS4JALCwuCBcPCwUJg4WERYKGwiKiQ8pyLJOFdLiwsCBYMi+KcW2PSq4w1Nt/jRGYYP8OEGUbLxsXJiOYm4sabGcbOMFQ203ZkR5QbnmHcDCMzTHkdWMeTEcpNmGF0hom4CeV1QDqtUZY399zqfWen0wIQet1oKBY6k6F0M5O5GU2xMxOnoTMFf9v5OnT7nYfOzqahc+R86FRv1bneqrt6qy71Vt3XW/VQb9W13qrHaquu9T5Ntd6nqf7vpym7lEwc3wx9Mza2h67vu6e7/KT8/MEBZwzT+6Yx5jVNCj/tfRqmD+G26+ajw9BPS3eL02M6dgrW5emyPD2kdNI83X9peliaHiT9UQ+e8nT90vS4OD2mO1NNvmbKB8hY+nQ8TTZPt0vTldOs6rvKEH1ienY3XcbWz/bQtdt+d90drhdfhvu0WYzN06/nv1fGzr8B","file_map":{"25":{"source":"use crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\nglobal TWO_POW_64: Field = 0x10000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(mut x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 64 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low_lower_64 = (x as u64) as Field;\n    x = (x - low_lower_64) / TWO_POW_64;\n    let low_upper_64 = (x as u64) as Field;\n\n    let high = (x - low_upper_64) / TWO_POW_64;\n    let low = low_upper_64 * TWO_POW_64 + low_lower_64;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nfn compute_lt(x: Field, y: Field, num_bytes: u32) -> bool {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n    let y_bytes: [u8; 32] = y.to_le_bytes();\n    let mut x_is_lt = false;\n    let mut done = false;\n    for i in 0..num_bytes {\n        if (!done) {\n            let x_byte = x_bytes[num_bytes - 1 - i];\n            let y_byte = y_bytes[num_bytes - 1 - i];\n            let bytes_match = x_byte == y_byte;\n            if !bytes_match {\n                x_is_lt = x_byte < y_byte;\n                done = true;\n            }\n        }\n    }\n    x_is_lt\n}\n\nfn compute_lte(x: Field, y: Field, num_bytes: u32) -> bool {\n    if x == y {\n        true\n    } else {\n        compute_lt(x, y, num_bytes)\n    }\n}\n\nunconstrained fn lt_32_hint(x: Field, y: Field) -> bool {\n    compute_lt(x, y, 32)\n}\n\nunconstrained fn lte_16_hint(x: Field, y: Field) -> bool {\n    compute_lte(x, y, 16)\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    unsafe {\n        let borrow = lte_16_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(compute_lt(b, a, 32));\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        compute_lt(b, a, 32)\n    } else if a == b {\n        false\n    } else {\n        // Take a hint of the comparison and verify it\n        unsafe {\n            if lt_32_hint(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{\n        decompose, compute_lt, assert_gt, gt, TWO_POW_128, compute_lte, PLO, PHI,\n    };\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    fn check_compute_lt() {\n        assert(compute_lt(0, 1, 16));\n        assert(compute_lt(0, 0x100, 16));\n        assert(compute_lt(0x100, TWO_POW_128 - 1, 16));\n        assert(!compute_lt(0, TWO_POW_128, 16));\n    }\n\n    #[test]\n    fn check_compute_lte() {\n        assert(compute_lte(0, 1, 16));\n        assert(compute_lte(0, 0x100, 16));\n        assert(compute_lte(0x100, TWO_POW_128 - 1, 16));\n        assert(!compute_lte(0, TWO_POW_128, 16));\n\n        assert(compute_lte(0, 0, 16));\n        assert(compute_lte(0x100, 0x100, 16));\n        assert(compute_lte(TWO_POW_128 - 1, TWO_POW_128 - 1, 16));\n        assert(compute_lte(TWO_POW_128, TWO_POW_128, 16));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n","path":"std/field/bn254.nr"},"29":{"source":"pub mod poseidon;\npub mod mimc;\npub mod poseidon2;\npub mod keccak;\npub mod sha256;\npub mod sha512;\n\nuse crate::default::Default;\nuse crate::uint128::U128;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n// Kept for backwards compatibility\npub use sha256::{digest, sha256, sha256_compression, sha256_var};\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars)[0]\n}\n\n#[field(bn254)]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n// docs:start:keccak256\npub fn keccak256<let N: u32>(input: [u8; N], message_size: u32) -> [u8; 32]\n// docs:end:keccak256\n{\n    crate::hash::keccak::keccak256(input, message_size)\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: StructDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher<H>\nwhere\n    H: Hasher,\n{\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl Hash for U128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self.lo as Field);\n        H::write(state, self.hi as Field);\n    }\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"70":{"source":"// Nahualli ZK Proof Circuit - Test Completed\n// Proves that a user has completed a psychometric test with valid scores\n\n// Private inputs:\n// - scores: array of 5 trait scores (0-100 each)\n// - salt: random value for commitment\n\n// Public outputs:\n// - commitment: hash of scores + salt (proves ownership without revealing scores)\n\nfn main(\n    score1: Field,          // Private: first trait score\n    score2: Field,          // Private: second trait score  \n    score3: Field,          // Private: third trait score\n    score4: Field,          // Private: fourth trait score\n    score5: Field,          // Private: fifth trait score\n    salt: Field,            // Private: random salt\n) -> pub Field {            // Returns: commitment hash\n    // 1. Verify all scores are in valid range (0-100)\n    let s1 = score1 as u64;\n    let s2 = score2 as u64;\n    let s3 = score3 as u64;\n    let s4 = score4 as u64;\n    let s5 = score5 as u64;\n    \n    assert(s1 <= 100, \"Score 1 out of range\");\n    assert(s2 <= 100, \"Score 2 out of range\");\n    assert(s3 <= 100, \"Score 3 out of range\");\n    assert(s4 <= 100, \"Score 4 out of range\");\n    assert(s5 <= 100, \"Score 5 out of range\");\n    \n    // 2. Compute and return commitment (Pedersen hash of all scores + salt)\n    let commitment = std::hash::pedersen_hash([score1, score2, score3, score4, score5, salt]);\n    commitment\n}\n\n#[test]\nfn test_valid_completion() {\n    let s1: Field = 75;\n    let s2: Field = 60;\n    let s3: Field = 80;\n    let s4: Field = 55;\n    let s5: Field = 70;\n    let salt: Field = 12345;\n    \n    let commitment = main(s1, s2, s3, s4, s5, salt);\n    assert(commitment == std::hash::pedersen_hash([s1, s2, s3, s4, s5, salt]));\n}\n","path":"/Users/jazz/projects/nahualli/circuits/test_completed/src/main.nr"}},"names":["main"],"brillig_names":["decompose_hint","directive_integer_quotient","directive_invert"]}